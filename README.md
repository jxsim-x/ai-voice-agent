# ğŸ¤– Zody â€“ Your Humourous AI Robot Companion  

![Build](https://img.shields.io/badge/build-passing-brightgreen)  
![Made with](https://img.shields.io/badge/Made%20with-FastAPI-009688)  
![Challenge](https://img.shields.io/badge/30Days-Voice%20Agents-orange)  

---

## ğŸ—£ï¸ Tagline  
**"Talk. Ask. Discover. Zody listens, understands, and speaks back in real-time."**

---

## ğŸ“– Description  
Zody is a fully functional **conversational AI voice agent** built in just **30 days**.  
It listens to your voice, detects when you finish speaking, and then uses:  

- ğŸ™ï¸ **AssemblyAI** â†’ Transcription & Turn Detection  
- ğŸ§  **Gemini 2.5 Flash** â†’ Conversational Intelligence  
- ğŸµ **Murf AI** â†’ Natural Voice Responses  

With **real-time streaming playback**, Zody gives a seamless back-and-forth conversation.  
It also comes with smart skills like **Weather Forecasting** powered by **Visual Crossing API**.  

---

## ğŸŒ Demo & Deployment  
- **Hosted App** â†’ [Zody on Render](https://zody-voice-agent.onrender.com)  

ğŸ“¸ **Screenshots & Proofs** (place your files here later):  
- ![UI Screenshot](docs/images/ui.png) *(Premium beige theme with golden text âœ¨)*  
- ![Conversation Demo GIF](docs/images/demo.gif)   

---

## ğŸ› ï¸ Tech Stack  

**Backend** â†’ Python, FastAPI, WebSockets, Uvicorn, Gunicorn  
**Frontend** â†’ HTML, CSS, JavaScript (Premium beige + golden UI)  
**AI/ML Services**:  
- AssemblyAI â†’ Speech-to-Text (Realtime + Turn Detection)  
- Gemini 2.5 Flash (Google Generative AI) â†’ Conversational LLM  
- Murf AI â†’ Text-to-Speech (Streaming Voice Synthesis)  

**APIs**: Visual Crossing Weather API  
**Audio Processing**: Pydub  
**Utilities**: python-dotenv, logging, cleanup scripts  

---

## âš™ï¸ Installation / Setup (Local Development)  

```bash
# Clone the Repository
git clone https://github.com/<your-username>/zody-voice-agent.git
cd zody-voice-agent

# Create a Virtual Environment & Activate
python -m venv .venv
source .venv/bin/activate   # Mac/Linux
.venv\Scripts\activate      # Windows

# Install Dependencies
pip install -r requirements.txt

# Create .env file in root and add:
GEMINI_API_KEY=your_google_gemini_key
ASSEMBLYAI_API_KEY=your_assemblyai_key
MURF_API_KEY=your_murf_key
WEATHER_API_KEY=your_visual_crossing_key

# Run the Server
uvicorn main:app --reload
# App will be live at â†’ http://localhost:8000/
```

---

## ğŸš€ Core Features

| ğŸ¤ **Voice Input** | ğŸ§  **AI Processing** | ğŸµ **Natural TTS** |
|:---:|:---:|:---:|
| One-click recording | Gemini 2.5 Flash | Murf AI voices |
| Turn detection | Conversational AI | Streaming playback |

| ğŸŒ¤ï¸ **Weather API** | âš¡ **Real-time** | ğŸ’¬ **Memory Chat** |
|:---:|:---:|:---:|
| Visual Crossing | Low latency | Session memory |
| Live forecasts | WebSocket streaming | Continuous talk |

---

## ğŸ§‘â€ğŸ’» How to Use

### End Users (Web UI)
1. Open `localhost:8000` or Render link
2. Click ğŸ¤ **Record** â†’ Start speaking
3. Zody will â†’ Listen â†’ Transcribe â†’ Think â†’ Speak back
4. Conversation continues hands-free until you hit Stop

### Developers (API Endpoints)

**Web UI**: `/`

**WebSocket**:
- `/ws` â†’ Echo bot
- `/ws/stream-audio` â†’ Audio streaming
- `/ws/transcribe-stream` â†’ Live transcription
- `/ws/llm-stream` â†’ Full pipeline (STT â†’ LLM â†’ TTS)

**REST**:
- `POST /generate-audio` â†’ Text â†’ Voice
- `POST /upload-audio` â†’ Upload audio
- `POST /tts/echo` â†’ Transcribe + Echo
- `POST /llm/query` â†’ One-shot query
- `POST /agent/chat/{session_id}` â†’ Memory-enabled chat

---

## ğŸ“‚ Project Structure

```
backend/
â”œâ”€â”€ frontend/        # Web UI
â”œâ”€â”€ schemas/         # Request/response models
â”œâ”€â”€ services/        # STT, LLM, TTS, Weather, etc.
â”œâ”€â”€ streaming/       # Audio streaming sessions
â”œâ”€â”€ tmp/             # Temporary audio files
â”œâ”€â”€ uploads/         # Uploaded audio files
â”œâ”€â”€ utils/           # Logging, cleanup, helpers
â”œâ”€â”€ backup_/         # Backup files/configs
â”‚
â”œâ”€â”€ .env             # Environment variables
â”œâ”€â”€ .gitignore       # Git ignore rules
â”œâ”€â”€ config.py        # Configurations
â”œâ”€â”€ main.py          # FastAPI entry point
â”œâ”€â”€ render.yaml      # Deployment config
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ structure.txt    # Debugging dump
â””â”€â”€ voice_agent.log  # Logs
```

---

## ğŸ”‘ Configuration & Env Variables

`.env` file example:

```ini
GEMINI_API_KEY=your_google_gemini_key
ASSEMBLYAI_API_KEY=your_assemblyai_key
MURF_API_KEY=your_murf_key
WEATHER_API_KEY=your_visual_crossing_key
```

**Bonus Security Feature**:
- Users can paste their own API keys directly in the UI
- Keys are stored only in browser memory â†’ deleted after refresh

---

## ğŸ”® Future Scope

- ğŸ­ Add more personas (Pirate Zody, Coach Zody, etc.)
- ğŸŒ Multi-language support (Hindi, Arabic, etc.)
- ğŸ“± Mobile app (Android/iOS)
- ğŸ’¾ Cloud memory for long-term conversations
- ğŸ§  Add more skills (reminders, jokes, news, small talk)
- ğŸ”Š Custom TTS voices for personality

---

## ğŸ’¡ Motivation

Built as part of the **30 Days of AI Voice Agents Challenge**.  
I wanted to prove that with dedication + curiosity, even in just 30 days,  
I could engineer an AI companion robot that listens, understands, and responds naturally.

---

## ğŸ™Œ Acknowledgements

- **AssemblyAI** â†’ Real-time speech-to-text
- **Google Gemini 2.5 Flash** â†’ Conversational intelligence
- **Murf AI** â†’ Natural text-to-speech
- **Visual Crossing** â†’ Weather API
- **FastAPI & Uvicorn** â†’ Backend framework
- **30 Days of AI Voice Agents Challenge (Murf AI)** â†’ Inspiration

---

## ğŸ“¬ Contact

ğŸ‘¨â€ğŸ’» **Muhammed Jasim Nisam**

- **LinkedIn** â†’ [linkedin.com/in/muhammed-jassim-nisam-656973277](https://linkedin.com/in/muhammed-jassim-nisam-656973277)
- **GitHub** â†’ [github.com/jxsim-x](https://github.com/jxsim-x)
- **ğŸ“§ Email** â†’ jasimnisam123@gmail.com

---

## ğŸ“œ License

This project is licensed under the **MIT License**.  
Feel free to fork, modify, and build upon Zody ğŸ‰
